# Architecture â€” ArXiv AI Paper Digest Agent

This document defines the system architecture, component design, data flows, and prompt specifications for the ArXiv AI Paper Digest Agent described in `docs/SCOPE.md`.

---

## 1. System Overview

The agent is a **linear pipeline** that runs once daily via GitHub Actions. There are no persistent servers, no databases, and no user-facing APIs â€” just a scheduled job that collects, analyzes, and emails.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              ARXIV AI PAPER DIGEST AGENT                                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    DATA       â”‚    â”‚   STAGE 1    â”‚    â”‚   STAGE 2    â”‚    â”‚    EMAIL     â”‚    â”‚  EMAIL â”‚ â”‚
â”‚  â”‚  COLLECTOR    â”‚â”€â”€â”€â–¶â”‚   RANKER     â”‚â”€â”€â”€â–¶â”‚    DEEP      â”‚â”€â”€â”€â–¶â”‚  COMPOSER   â”‚â”€â”€â”€â–¶â”‚ SENDER â”‚ â”‚
â”‚  â”‚              â”‚    â”‚              â”‚    â”‚  ANALYZER    â”‚    â”‚             â”‚    â”‚        â”‚ â”‚
â”‚  â”‚ arXiv API    â”‚    â”‚ All titles + â”‚    â”‚ Full PDFs    â”‚    â”‚ HTML email  â”‚    â”‚ Gmail  â”‚ â”‚
â”‚  â”‚ ~200 papers  â”‚    â”‚ abstracts    â”‚    â”‚ for top 5    â”‚    â”‚ template    â”‚    â”‚ SMTP   â”‚ â”‚
â”‚  â”‚              â”‚    â”‚ â†’ top 10     â”‚    â”‚ + blurbs 6-10â”‚    â”‚             â”‚    â”‚        â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                   â”‚                   â”‚                   â”‚               â”‚        â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â”‚
â”‚                                              â”‚                                               â”‚
â”‚                                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â”‚
â”‚                                    â”‚   ERROR HANDLER    â”‚                                    â”‚
â”‚                                    â”‚                    â”‚                                    â”‚
â”‚                                    â”‚ Catches failures   â”‚                                    â”‚
â”‚                                    â”‚ at any stage â†’     â”‚                                    â”‚
â”‚                                    â”‚ sends error email  â”‚                                    â”‚
â”‚                                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â”‚
â”‚                                                                                              â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚                              CONFIGURATION LAYER                                      â”‚    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚    â”‚
â”‚  â”‚  â”‚ User Profile   â”‚  â”‚ Subscribers    â”‚  â”‚ Environment    â”‚  â”‚ Email Template   â”‚   â”‚    â”‚
â”‚  â”‚  â”‚ (JSON)         â”‚  â”‚ (JSON)         â”‚  â”‚ Variables      â”‚  â”‚ (Jinja2/HTML)    â”‚   â”‚    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Design Principles

| Principle | Implementation |
|-----------|----------------|
| **Stateless** | No database, no persistent state between runs. Each run is independent. |
| **Fail-safe** | Any stage failure triggers an error email; never fails silently. |
| **Idempotent** | Re-running the same day produces the same results (same input papers â†’ same output). |
| **Cost-conscious** | Use cheaper models where quality allows; full Claude only for deep analysis. |
| **Simple** | No orchestration framework, no queues, no microservices. Just Python functions called in sequence. |

---

## 2. Pipeline Flow â€” Detailed

### 2.1 End-to-End Sequence

```
GitHub Actions Cron (6 AM ET / 11:00 UTC, Tue-Sat)
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 1. DATA COLLECTOR                                                â”‚
â”‚    â€¢ Fetch all cs.AI papers from previous day via arXiv API      â”‚
â”‚    â€¢ Extract: arxiv_id, title, authors, abstract, comments,      â”‚
â”‚      subjects, pdf_url, html_url                                 â”‚
â”‚    â€¢ Deduplicate by arxiv_id                                     â”‚
â”‚    â€¢ Output: List[Paper] (~150-200 papers)                       â”‚
â”‚                                                                   â”‚
â”‚    IF 0 papers found â†’ send "quiet day" email â†’ EXIT              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 2. STAGE 1: RANKER (LLM Call #1)                                 â”‚
â”‚    â€¢ Input: All papers (titles + abstracts + authors + comments)  â”‚
â”‚             + User Profile                                        â”‚
â”‚    â€¢ Model: Claude 3.5 Sonnet (balance of cost and quality)       â”‚
â”‚    â€¢ Output: Ranked top 10-15 papers with justifications          â”‚
â”‚    â€¢ Split: Top 5 â†’ deep analysis, #6-10 â†’ blurbs                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
                    â”‚         â”‚
              Top 5 â–¼    #6-10 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 3a. PDF FETCHER    â”‚  â”‚ 3c. BLURB GENERATOR (LLM Call #7)       â”‚
â”‚  â€¢ Download PDFs   â”‚  â”‚  â€¢ Input: 5 abstracts + user profile    â”‚
â”‚    for top 5       â”‚  â”‚  â€¢ Model: Claude 3.5 Sonnet              â”‚
â”‚  â€¢ Extract text    â”‚  â”‚  â€¢ Output: 100-150 word blurb per paper  â”‚
â”‚  â€¢ Rate-limited    â”‚  â”‚  â€¢ Single call for all 5 blurbs          â”‚
â”‚    (3s between)    â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
          â”‚                                   â”‚
          â–¼                                   â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚ 3b. DEEP ANALYZER (LLM Calls #2-6)      â”‚   â”‚
â”‚  â€¢ Input: Full paper text + user profile â”‚   â”‚
â”‚  â€¢ Model: Claude 3.5 Sonnet              â”‚   â”‚
â”‚  â€¢ Output: 1,000-2,000 word summary      â”‚   â”‚
â”‚  â€¢ One call per paper (5 calls total)    â”‚   â”‚
â”‚  â€¢ Summary follows format spec from      â”‚   â”‚
â”‚    SCOPE.md (So What â†’ Core Idea â†’       â”‚   â”‚
â”‚    How It Works â†’ Results â†’ Limitations  â”‚   â”‚
â”‚    â†’ Applications & Opportunities)       â”‚   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
                      â”‚                       â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 4. EMAIL COMPOSER                                                â”‚
â”‚    â€¢ Input: 5 deep summaries + 5 blurbs + paper metadata         â”‚
â”‚    â€¢ Template: Jinja2 HTML template                               â”‚
â”‚    â€¢ Output: Complete HTML email body                             â”‚
â”‚    â€¢ No LLM needed â€” pure template rendering                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ 5. EMAIL SENDER                                                  â”‚
â”‚    â€¢ Input: HTML email + subscriber list                          â”‚
â”‚    â€¢ Method: Gmail SMTP with App Password                         â”‚
â”‚    â€¢ Sends to each active subscriber                              â”‚
â”‚    â€¢ Logs success/failure per recipient                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 LLM Call Summary

| Call # | Stage | Model | Input Size | Output Size | Purpose |
|--------|-------|-------|------------|-------------|---------|
| 1 | Stage 1: Ranker | Claude 3.5 Sonnet | ~60-80K tokens (all papers) | ~2K tokens (ranked list) | Rank all papers, select top 10 |
| 2-6 | Stage 2: Deep Analyzer | Claude 3.5 Sonnet | ~15-30K tokens each (full paper) | ~2-3K tokens each (summary) | Deep 1,000-2,000 word summaries |
| 7 | Stage 2: Blurb Generator | Claude 3.5 Sonnet | ~3K tokens (5 abstracts) | ~1K tokens (5 blurbs) | Short blurbs for #6-10 |

**Total LLM calls per run:** 7
**Estimated daily cost:** ~$0.30â€“0.60

---

## 3. Component Details

### 3.1 Data Collector

**Responsibility:** Fetch all `cs.AI` papers published on arXiv the previous day.

**Input:** Date (previous business day)
**Output:** `List[Paper]` â€” structured paper objects

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   arXiv API      â”‚      â”‚  Paper Parser    â”‚      â”‚   Deduplicator   â”‚
â”‚                  â”‚      â”‚                  â”‚      â”‚                  â”‚
â”‚ Fetch cs.AI      â”‚â”€â”€â”€â”€â”€â–¶â”‚ Extract fields:  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Remove duplicate â”‚
â”‚ papers for       â”‚      â”‚ â€¢ arxiv_id       â”‚      â”‚ arxiv_ids        â”‚
â”‚ target date      â”‚      â”‚ â€¢ title          â”‚      â”‚ (cross-listings) â”‚
â”‚                  â”‚      â”‚ â€¢ authors        â”‚      â”‚                  â”‚
â”‚ Rate-limited:    â”‚      â”‚ â€¢ abstract       â”‚      â”‚ Output:          â”‚
â”‚ 3s between       â”‚      â”‚ â€¢ comments       â”‚      â”‚ List[Paper]      â”‚
â”‚ requests         â”‚      â”‚ â€¢ subjects       â”‚      â”‚                  â”‚
â”‚                  â”‚      â”‚ â€¢ pdf_url        â”‚      â”‚                  â”‚
â”‚                  â”‚      â”‚ â€¢ html_url       â”‚      â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Paper Data Model:**

```python
@dataclass
class Paper:
    arxiv_id: str           # e.g., "2602.17663"
    title: str              # Paper title
    authors: list[str]      # List of author names
    abstract: str           # Full abstract text
    comments: str | None    # e.g., "Accepted at ICLR 2026"
    subjects: list[str]     # e.g., ["cs.AI", "cs.CL"]
    pdf_url: str            # https://arxiv.org/pdf/2602.17663
    html_url: str           # https://arxiv.org/html/2602.17663
    published_date: str     # ISO date
```

**API Strategy:**

| Approach | Pros | Cons | Recommendation |
|----------|------|------|----------------|
| `arxiv` Python package | Clean API, handles pagination | May need date filtering logic | âœ… Primary |
| Atom/RSS feed | Real-time, lightweight | Limited metadata | Fallback |
| Scraping the HTML listing | Gets exactly what the page shows | Fragile, against ToS spirit | âŒ Avoid |

**Date Handling:**
- The agent runs Tuesdayâ€“Saturday
- It always fetches **the previous business day's** papers
- Friday's run fetches Thursday's papers; Saturday's run fetches Friday's papers
- If no papers are found (holiday), the pipeline sends a quiet day notice and exits

---

### 3.2 Stage 1: Ranker

**Responsibility:** Evaluate all papers against the user profile and return a ranked top 10â€“15.

**Input:** `List[Paper]` (all papers) + User Profile (from config)
**Output:** `RankedResults` â€” top 10-15 papers with justifications, split into "deep dive" (top 5) and "blurb" (next 5) tiers

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        STAGE 1: RANKER                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  Input Assembly:                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                â”‚
â”‚  â”‚  User Profile       â”‚  â”‚  All Papers          â”‚                â”‚
â”‚  â”‚  (from config)      â”‚  â”‚  (from collector)    â”‚                â”‚
â”‚  â”‚                     â”‚  â”‚                      â”‚                â”‚
â”‚  â”‚  â€¢ Interests        â”‚  â”‚  â€¢ Title             â”‚                â”‚
â”‚  â”‚  â€¢ Deprioritize     â”‚  â”‚  â€¢ Authors           â”‚                â”‚
â”‚  â”‚  â€¢ Sources          â”‚  â”‚  â€¢ Abstract          â”‚                â”‚
â”‚  â”‚  â€¢ Preferences      â”‚  â”‚  â€¢ Comments          â”‚                â”‚
â”‚  â”‚  â€¢ Wildcard note    â”‚  â”‚  â€¢ Subjects          â”‚                â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                â”‚
â”‚             â”‚                        â”‚                            â”‚
â”‚             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                          â”‚                                        â”‚
â”‚                          â–¼                                        â”‚
â”‚                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚                â”‚   LLM Call #1    â”‚                               â”‚
â”‚                â”‚   Claude Sonnet  â”‚                               â”‚
â”‚                â”‚                  â”‚                               â”‚
â”‚                â”‚  "Rank these     â”‚                               â”‚
â”‚                â”‚   papers by      â”‚                               â”‚
â”‚                â”‚   relevance to   â”‚                               â”‚
â”‚                â”‚   this profile"  â”‚                               â”‚
â”‚                â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â”‚                         â”‚                                        â”‚
â”‚                         â–¼                                        â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                              â”‚
â”‚              â”‚  Ranked Output     â”‚                              â”‚
â”‚              â”‚                    â”‚                              â”‚
â”‚              â”‚  Top 5:  â†’ Deep    â”‚                              â”‚
â”‚              â”‚  #6-10:  â†’ Blurbs  â”‚                              â”‚
â”‚              â”‚  Each with:        â”‚                              â”‚
â”‚              â”‚  â€¢ Rank            â”‚                              â”‚
â”‚              â”‚  â€¢ Justification   â”‚                              â”‚
â”‚              â”‚  â€¢ Relevance tier  â”‚                              â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                              â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Ranking Output Schema:**

```json
{
  "total_papers_evaluated": 187,
  "ranking_date": "2026-02-20",
  "top_papers": [
    {
      "rank": 1,
      "arxiv_id": "2602.17560",
      "title": "ODESteer: A Unified ODE-Based Steering Framework...",
      "tier": "deep_dive",
      "justification": "Directly addresses LLM alignment through a novel ODE-based framework...",
      "relevance_tags": ["LLM agents", "AI reasoning"],
      "source_match": "ICLR 2026 accepted",
      "is_wildcard": false
    }
  ]
}
```

---

### 3.3 Stage 2: PDF Fetcher & Text Extractor

**Responsibility:** Download and extract readable text from the top 5 papers' PDFs.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   PDF Download   â”‚      â”‚  Text Extraction â”‚      â”‚  Text Cleanup    â”‚
â”‚                  â”‚      â”‚                  â”‚      â”‚                  â”‚
â”‚ Download PDF     â”‚â”€â”€â”€â”€â”€â–¶â”‚ Extract text     â”‚â”€â”€â”€â”€â”€â–¶â”‚ Remove:          â”‚
â”‚ from arXiv       â”‚      â”‚ from PDF using   â”‚      â”‚ â€¢ Page headers   â”‚
â”‚                  â”‚      â”‚ pymupdf          â”‚      â”‚ â€¢ References     â”‚
â”‚ Rate-limited:    â”‚      â”‚                  â”‚      â”‚   section (opt.) â”‚
â”‚ 3s between       â”‚      â”‚ Fallback:        â”‚      â”‚ â€¢ Figure/table   â”‚
â”‚ downloads        â”‚      â”‚ Try HTML version â”‚      â”‚   captions (opt.)â”‚
â”‚                  â”‚      â”‚ if PDF fails     â”‚      â”‚                  â”‚
â”‚                  â”‚      â”‚                  â”‚      â”‚ Truncate if      â”‚
â”‚                  â”‚      â”‚                  â”‚      â”‚ > 80K tokens     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Text Extraction Strategy:**

| Method | When to Use | Pros | Cons |
|--------|-------------|------|------|
| **PyMuPDF (fitz)** | Primary â€” works on all PDFs | Fast, reliable, good text extraction | Some formatting artifacts |
| **arXiv HTML** | Fallback / preferred when available | Clean text, proper structure | Not all papers have HTML versions |

**Text Cleanup Rules:**
1. Remove repeated headers/footers (page numbers, running titles)
2. Optionally trim the References section (saves tokens, not needed for summary)
3. If extracted text exceeds ~80K tokens (~60K words), truncate from the end (keeping abstract, introduction, methodology, results)
4. Preserve section headings for structural context

**Token Budget per Paper:**

| Component | Estimated Tokens |
|-----------|-----------------|
| Full paper text | 15,000â€“30,000 |
| System prompt + user profile | ~2,000 |
| Summary format instructions | ~500 |
| **Total input** | **~17,500â€“32,500** |
| Generated summary (1,000-2,000 words) | ~1,500â€“3,000 |
| **Headroom in 200K context** | âœ… Plenty |

---

### 3.4 Stage 2: Deep Analyzer

**Responsibility:** Generate a detailed, accessible, 1,000â€“2,000 word summary of each top-5 paper.

**Input:** Full paper text + User Profile + Summary format spec
**Output:** Structured summary following the 6-section format from SCOPE.md
**Model:** Claude 3.5 Sonnet
**Calls:** 5 (one per paper, sequential)

```
For each of the top 5 papers:
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  Full Paper Text â”‚      â”‚   LLM Call       â”‚      â”‚  Structured      â”‚
    â”‚  + User Profile  â”‚â”€â”€â”€â”€â”€â–¶â”‚   Claude Sonnet  â”‚â”€â”€â”€â”€â”€â–¶â”‚  Summary         â”‚
    â”‚  + Format Spec   â”‚      â”‚                  â”‚      â”‚                  â”‚
    â”‚                  â”‚      â”‚  Generate        â”‚      â”‚  â€¢ So What?      â”‚
    â”‚                  â”‚      â”‚  1,000-2,000     â”‚      â”‚  â€¢ Core Idea     â”‚
    â”‚                  â”‚      â”‚  word summary    â”‚      â”‚  â€¢ How It Works  â”‚
    â”‚                  â”‚      â”‚                  â”‚      â”‚  â€¢ Key Results   â”‚
    â”‚                  â”‚      â”‚                  â”‚      â”‚  â€¢ Limitations   â”‚
    â”‚                  â”‚      â”‚                  â”‚      â”‚  â€¢ Applications  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Why Sequential, Not Parallel?**
- arXiv rate limiting means PDFs are downloaded sequentially anyway
- Sequential calls are simpler to debug and log
- Total time for 5 calls â‰ˆ 2â€“3 minutes â€” well within our 15-minute budget
- Parallel calls can be added later if needed

---

### 3.5 Stage 2: Blurb Generator

**Responsibility:** Generate short blurbs for papers ranked #6â€“10.

**Input:** 5 abstracts + User Profile
**Output:** 100â€“150 word blurb per paper
**Model:** Claude 3.5 Sonnet
**Calls:** 1 (all 5 blurbs in a single call)

This is a single, cheap LLM call. No PDF download needed â€” abstracts are sufficient for short blurbs.

---

### 3.6 Email Composer

**Responsibility:** Assemble the final HTML email from summaries, blurbs, and metadata.

**Input:** 5 deep summaries + 5 blurbs + paper metadata + daily stats
**Output:** Complete HTML email string
**LLM:** None â€” pure template rendering

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Template Data   â”‚      â”‚  Jinja2 Engine   â”‚      â”‚  HTML Email      â”‚
â”‚                  â”‚      â”‚                  â”‚      â”‚                  â”‚
â”‚  â€¢ Deep summariesâ”‚â”€â”€â”€â”€â”€â–¶â”‚ Render template  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Ready to send    â”‚
â”‚  â€¢ Blurbs        â”‚      â”‚ with data        â”‚      â”‚                  â”‚
â”‚  â€¢ Paper metadataâ”‚      â”‚                  â”‚      â”‚ Includes:        â”‚
â”‚  â€¢ Date          â”‚      â”‚ Apply styling    â”‚      â”‚ â€¢ Inline CSS     â”‚
â”‚  â€¢ Stats         â”‚      â”‚                  â”‚      â”‚ â€¢ PDF/HTML links â”‚
â”‚  â€¢ Profile name  â”‚      â”‚                  â”‚      â”‚ â€¢ Stats footer   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Template Sections:**

| Section | Content | Data Source |
|---------|---------|-------------|
| Header | Digest title, date, paper count | Pipeline metadata |
| Deep Dives (1-5) | Title, authors, venue, links, full summary | Deep Analyzer output |
| Quick Reads (6-10) | Title, authors, links, blurb | Blurb Generator output |
| Footer | Stats, profile name, update instructions | Config + metadata |

**Email Styling Notes:**
- Use **inline CSS** (many email clients strip `<style>` blocks)
- Keep layout single-column for mobile compatibility
- Use web-safe fonts (Georgia, Arial, system fonts)
- Test with Gmail rendering (primary target)

---

### 3.7 Email Sender

**Responsibility:** Deliver the composed email to all active subscribers.

**Input:** HTML email string + subscriber list
**Output:** Delivery status per recipient

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Subscriber List â”‚      â”‚  Gmail SMTP      â”‚      â”‚  Delivery Log    â”‚
â”‚  (from config)   â”‚      â”‚                  â”‚      â”‚                  â”‚
â”‚                  â”‚â”€â”€â”€â”€â”€â–¶â”‚ For each active  â”‚â”€â”€â”€â”€â”€â–¶â”‚ Log per          â”‚
â”‚  Filter: active  â”‚      â”‚ subscriber:      â”‚      â”‚ recipient:       â”‚
â”‚  only            â”‚      â”‚ â€¢ Connect SMTP   â”‚      â”‚ â€¢ email          â”‚
â”‚                  â”‚      â”‚ â€¢ Send email     â”‚      â”‚ â€¢ status         â”‚
â”‚                  â”‚      â”‚ â€¢ Close          â”‚      â”‚ â€¢ timestamp      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**SMTP Configuration:**

| Setting | Value |
|---------|-------|
| Server | `smtp.gmail.com` |
| Port | `587` (TLS) |
| Auth | Gmail App Password |
| From | Configured sender address |
| Subject | `ğŸ“° ArXiv AI Digest â€” {Date}` |
| Content-Type | `text/html` |

---

### 3.8 Error Handler

**Responsibility:** Catch failures at any pipeline stage and send an error notification.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ERROR HANDLER                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  Wraps entire pipeline in try/except                              â”‚
â”‚                                                                    â”‚
â”‚  On failure:                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚
â”‚  â”‚  Capture Error   â”‚      â”‚  Send Error      â”‚                  â”‚
â”‚  â”‚                  â”‚      â”‚  Email           â”‚                  â”‚
â”‚  â”‚  â€¢ Stage name    â”‚â”€â”€â”€â”€â”€â–¶â”‚                  â”‚                  â”‚
â”‚  â”‚  â€¢ Error message â”‚      â”‚  To: subscribers â”‚                  â”‚
â”‚  â”‚  â€¢ Traceback     â”‚      â”‚  Subject: âš ï¸     â”‚                  â”‚
â”‚  â”‚  â€¢ Timestamp     â”‚      â”‚  ArXiv Digest    â”‚                  â”‚
â”‚  â”‚  â€¢ Papers found  â”‚      â”‚  Pipeline Error  â”‚                  â”‚
â”‚  â”‚    (if any)      â”‚      â”‚                  â”‚                  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚
â”‚                                                                    â”‚
â”‚  Error email contains:                                            â”‚
â”‚  â€¢ Which stage failed (Data Collector / Ranker / Analyzer / etc.) â”‚
â”‚  â€¢ Error message and type                                         â”‚
â”‚  â€¢ Truncated traceback (last 20 lines)                            â”‚
â”‚  â€¢ Timestamp (UTC + ET)                                           â”‚
â”‚  â€¢ Note: "Will retry on next scheduled run"                       â”‚
â”‚                                                                    â”‚
â”‚  Also: log full error to GitHub Actions console for debugging     â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Failure Modes & Handling:**

| Failure | Stage | Handling | User Impact |
|---------|-------|----------|-------------|
| arXiv API unreachable | Data Collector | Retry 3x with 30s backoff â†’ error email | No digest today |
| 0 papers returned (holiday) | Data Collector | Send quiet day notice â†’ exit cleanly | Gets notice |
| LLM API error | Ranker or Analyzer | Retry 2x â†’ error email | No digest today |
| LLM returns malformed JSON | Ranker | Retry with stricter prompt â†’ error email | No digest today |
| PDF download fails (1 paper) | PDF Fetcher | Skip paper, promote #6 to deep dive | Digest with 4 deep + 1 promoted |
| PDF text extraction fails | PDF Fetcher | Try HTML fallback â†’ if both fail, treat as blurb | Graceful degradation |
| Gmail SMTP error | Email Sender | Retry 3x â†’ log error (can't email about email failure) | No digest; visible in GH Actions logs |
| Summary too short (<800 words) | Deep Analyzer | Re-prompt once with "please expand" â†’ accept if improved | Slightly shorter summary |

---

## 4. Configuration Files

### 4.1 File Structure

```
config/
â”œâ”€â”€ user_profile.json       # Interests, priorities, sources
â”œâ”€â”€ subscribers.json         # Email recipient list
â””â”€â”€ .env                     # API keys, SMTP credentials (not in repo)
```

### 4.2 User Profile (`config/user_profile.json`)

This is the full profile structure defined in `SCOPE.md`. The Ranker and Deep Analyzer both receive this as context.

### 4.3 Subscribers (`config/subscribers.json`)

```json
{
  "subscribers": [
    {
      "email": "andres@example.com",
      "name": "Andres",
      "active": true
    }
  ]
}
```

### 4.4 Environment Variables

| Variable | Purpose | Stored In |
|----------|---------|-----------|
| `ANTHROPIC_API_KEY` | Claude API authentication | GitHub Secrets |
| `GMAIL_ADDRESS` | Sender email address | GitHub Secrets |
| `GMAIL_APP_PASSWORD` | Gmail App Password for SMTP | GitHub Secrets |

---

## 5. Prompt Specifications

This section defines the exact prompt structure for each LLM-calling stage. These are the contracts the model must fulfill.

---

### 5.1 Stage 1: Ranker Prompt

**Purpose:** Evaluate all daily papers against the user profile, return a ranked top 10.

**Temperature:** 0.3 (structured, consistent ranking)

**System Prompt:**

```
You are an expert AI research curator. Your job is to read through a day's
worth of arXiv papers and identify the ones most relevant, impactful, and
interesting to a specific reader based on their profile.

You are thorough, fair, and intellectually curious. You don't just match
keywords â€” you understand the significance of research contributions and
can identify genuinely important work even when it doesn't perfectly match
the reader's stated interests.
```

**User Prompt:**

```
## Reader Profile

{user_profile_json}

## Today's Papers ({paper_count} total)

{for each paper:}
---
[{index}] arxiv_id: {arxiv_id}
Title: {title}
Authors: {authors}
Abstract: {abstract}
Comments: {comments or "None"}
Subjects: {subjects}
---

## Instructions

Evaluate ALL papers above against the reader's profile and return the top 10
most relevant papers, ranked from most to least important.

For each selected paper, provide:
1. The arxiv_id
2. A justification (2-3 sentences) explaining why this paper matters
   to this specific reader
3. Relevance tags (which profile interests it matches)
4. Whether this is a "wildcard" pick (innovative/revolutionary but
   outside the reader's stated interests)

RANKING CRITERIA (in priority order):
1. Topic relevance to primary interests (highest weight)
2. Novelty â€” new paradigm or method vs. incremental improvement
3. Practical applicability â€” can it be used in industry?
4. Source credibility â€” from a prioritized institution/lab? (boost, not gatekeeper)
5. Venue acceptance â€” accepted at a top conference? (noted in comments)
6. Breadth of impact â€” relevant across domains?
7. Wildcard potential â€” genuinely revolutionary even if outside stated interests?

IMPORTANT RULES:
- Primary interests get MUCH higher weight than secondary
- Papers matching "deprioritize" topics should be excluded unless
  they are truly exceptional
- Include at least 1 wildcard pick if anything qualifies
- If a paper is from a prioritized source, note it but don't rank it
  higher JUST for that â€” quality and relevance come first
- A great paper from an unknown lab should absolutely make the list

RETURN THIS EXACT JSON STRUCTURE:
{
  "total_papers_evaluated": <number>,
  "ranking_date": "<YYYY-MM-DD>",
  "top_papers": [
    {
      "rank": <1-10>,
      "arxiv_id": "<id>",
      "title": "<paper title>",
      "tier": "deep_dive" | "blurb",
      "justification": "<2-3 sentences>",
      "relevance_tags": ["<matching interest 1>", "<matching interest 2>"],
      "source_match": "<institution/venue note or null>",
      "is_wildcard": <true|false>
    }
  ]
}

Papers ranked 1-5 should have tier "deep_dive".
Papers ranked 6-10 should have tier "blurb".

Return ONLY valid JSON. No markdown, no commentary outside the JSON.
```

---

### 5.2 Stage 2: Deep Analyzer Prompt

**Purpose:** Generate a detailed, accessible summary of a single research paper.

**Temperature:** 0.5 (balanced â€” creative enough for good writing, grounded enough for accuracy)

**System Prompt:**

```
You are a world-class science communicator who makes cutting-edge AI research
accessible to smart professionals who aren't necessarily researchers. Think of
your audience as a tech-savvy executive or senior engineer who wants to
understand what's happening in AI without reading full papers.

Your writing style is:
- Clear and direct, never condescending
- Uses analogies and examples to explain complex ideas
- Includes specific results and numbers when they tell a story
- Honest about limitations â€” you don't overhype
- Engaging â€” the reader should want to finish the summary

You write in a professional but warm tone. No jargon without explanation.
No hand-waving. Every claim is grounded in what the paper actually says.
```

**User Prompt:**

```
## Reader Profile (for context on what matters to them)

{user_profile_json}

## Paper Metadata

Title: {title}
Authors: {authors}
arXiv ID: {arxiv_id}
Subjects: {subjects}
Comments: {comments or "None"}
Venue: {extracted venue or "Not specified"}

## Ranking Context

This paper was ranked #{rank} out of {total_papers} papers today.
Ranking justification: {justification_from_stage1}
Relevance tags: {relevance_tags}

## Full Paper Text

{full_paper_text}

## Instructions

Write a detailed summary of this paper following this EXACT structure.
Target length: 1,000-2,000 words total across all sections.

### 1. The "So What?" (1 paragraph)
Open with why this paper matters in plain language. What problem does it
solve? Why should a busy professional care? Lead with impact, not
technical details.

### 2. The Core Idea (2-3 paragraphs)
Explain the key insight or method in accessible terms. Use analogies
where they genuinely help. Assume the reader is intelligent but not a
specialist in this specific sub-field.

### 3. How It Works (2-3 paragraphs)
Walk through the approach clearly. Not a full technical deep dive, but
enough that the reader understands the mechanism. Skip heavy math â€”
explain the intuition behind the math. If there's a novel architecture
or pipeline, describe it step by step.

### 4. Key Results (1-2 paragraphs)
What did they find? How does it compare to previous work? Include
specific numbers, percentages, or benchmarks when they tell a
compelling story. Don't list every result â€” highlight the ones that
matter most.

### 5. Limitations & Open Questions (1 paragraph)
Be honest. What doesn't the paper address? What assumptions does it
make? What would need to happen for this to be practically useful at
scale? This section builds trust with the reader.

### 6. Real-World Applications & Opportunities (1-2 paragraphs)
Concrete examples of how this research could be applied in industry,
products, or businesses. What opportunities does it create? Who should
be paying attention â€” and what could they build with this? Connect it
to the reader's interests where relevant.

FORMAT RULES:
- Use markdown headers (### ) for each section
- Write in flowing prose, not bullet points (except where a short list
  genuinely aids clarity)
- Do NOT include the paper title or authors in the summary body â€” those
  are in the email template
- Do NOT start with "This paper..." â€” lead with the problem or insight
- Aim for the high end of the word range (closer to 2,000 than 1,000)
  when the paper warrants it
```

---

### 5.3 Blurb Generator Prompt

**Purpose:** Generate short blurbs for papers ranked #6â€“10.

**Temperature:** 0.4 (concise, focused)

**System Prompt:**

```
You are a concise AI research curator. You write sharp, informative blurbs
that help busy professionals decide whether to read a paper. Every word earns
its place.
```

**User Prompt:**

```
## Reader Profile

{user_profile_json}

## Papers to Summarize

{for each paper #6-10:}
---
[{rank}] arxiv_id: {arxiv_id}
Title: {title}
Authors: {authors}
Abstract: {abstract}
Comments: {comments or "None"}
Ranking justification: {justification_from_stage1}
---

## Instructions

For EACH paper above, write a blurb of 100-150 words that:

1. States the core contribution in 1-2 crisp sentences
2. Explains why it's noteworthy (what's new or different)
3. Ends with a "Read this if:" tag pointing to who should care

RETURN THIS EXACT JSON STRUCTURE:
{
  "blurbs": [
    {
      "arxiv_id": "<id>",
      "rank": <number>,
      "blurb": "<100-150 word blurb text>",
      "read_this_if": "<one-line tag, e.g., 'you're building multi-agent systems'>"
    }
  ]
}

Return ONLY valid JSON. No markdown, no commentary outside the JSON.
```

---

### 5.4 Temperature Guidelines

| Temperature | Rationale | Stages |
|-------------|-----------|--------|
| **0.3** | Consistent, structured output; minimal creative variance | Stage 1: Ranker |
| **0.4** | Concise and focused; slight creative flexibility | Blurb Generator |
| **0.5** | Balanced â€” good writing quality with factual grounding | Deep Analyzer |

---

### 5.5 Prompt Engineering Principles

| Principle | Application |
|-----------|-------------|
| **Structured output** | Always request JSON with explicit schema; easier to parse and validate |
| **Role-based system prompts** | Each stage has a distinct persona (curator vs. communicator vs. concise writer) |
| **Reader context** | Always include the user profile so the LLM tailors its output |
| **Explicit format rules** | Word counts, section structures, and anti-patterns ("Don't start with...") |
| **Grounding** | Deep Analyzer sees the full paper, not just abstract â€” summaries are grounded in actual content |
| **Audit trail** | Ranker justifications explain why each paper was selected â€” useful for debugging and trust |

---

## 6. Pipeline Timing Estimate

| Stage | Duration | Notes |
|-------|----------|-------|
| Data Collector | ~30-60s | arXiv API fetch + parsing, rate-limited |
| Stage 1: Ranker | ~15-30s | Single LLM call, large input |
| PDF Download (5 papers) | ~15-20s | 3s rate limit Ã— 5 papers |
| Text Extraction | ~5-10s | Local processing, fast |
| Deep Analyzer (5 papers) | ~2-4 min | 5 sequential LLM calls, ~30-45s each |
| Blurb Generator | ~10-15s | Single LLM call, small input |
| Email Composer | ~1s | Template rendering, no LLM |
| Email Sender | ~5-10s | SMTP connection + send |
| **Total** | **~4-7 minutes** | Well within 15-minute budget |

---

## 7. Directory Structure

```
arxiv-digest/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ workflows/
â”‚       â””â”€â”€ daily_digest.yml       # GitHub Actions cron job
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ user_profile.json          # Reader interests & preferences
â”‚   â””â”€â”€ subscribers.json           # Email recipient list
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # Pipeline orchestrator (entry point)
â”‚   â”œâ”€â”€ collector.py               # Data Collector â€” arXiv API
â”‚   â”œâ”€â”€ ranker.py                  # Stage 1 â€” LLM ranking
â”‚   â”œâ”€â”€ pdf_extractor.py           # PDF download + text extraction
â”‚   â”œâ”€â”€ analyzer.py                # Stage 2 â€” Deep summaries
â”‚   â”œâ”€â”€ blurb_generator.py         # Stage 2 â€” Short blurbs
â”‚   â”œâ”€â”€ email_composer.py          # HTML email assembly
â”‚   â”œâ”€â”€ email_sender.py            # Gmail SMTP delivery
â”‚   â””â”€â”€ error_handler.py           # Error capture + notification
â”‚
â”œâ”€â”€ templates/
â”‚   â””â”€â”€ digest_email.html          # Jinja2 email template
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_collector.py
â”‚   â”œâ”€â”€ test_ranker.py
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_email.py
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ SCOPE.md
â”‚   â”œâ”€â”€ ARCHITECTURE.md            # This document
â”‚   â”œâ”€â”€ TECH_STACK.md
â”‚   â””â”€â”€ EXECUTION_PLAN.md
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example                    # Template for environment variables
â””â”€â”€ .gitignore
```

**Module Responsibilities:**

| Module | Lines (est.) | LLM? | Description |
|--------|-------------|------|-------------|
| `main.py` | ~80 | No | Orchestrates the pipeline; calls each stage in sequence |
| `collector.py` | ~100 | No | Fetches papers from arXiv API, deduplicates |
| `ranker.py` | ~80 | Yes | Builds ranking prompt, calls Claude, parses response |
| `pdf_extractor.py` | ~120 | No | Downloads PDFs, extracts text, cleans up |
| `analyzer.py` | ~80 | Yes | Builds deep analysis prompt, calls Claude per paper |
| `blurb_generator.py` | ~60 | Yes | Builds blurb prompt, calls Claude once for all 5 |
| `email_composer.py` | ~60 | No | Loads Jinja2 template, renders with data |
| `email_sender.py` | ~60 | No | SMTP connection, sends to subscriber list |
| `error_handler.py` | ~50 | No | Try/except wrapper, error email formatting |

**Estimated total:** ~700 lines of Python (excluding tests and templates)

---

## 8. GitHub Actions Workflow

```yaml
# .github/workflows/daily_digest.yml
name: ArXiv AI Digest

on:
  schedule:
    # 11:00 UTC = 6:00 AM ET, Tuesday through Saturday
    - cron: '0 11 * * 2-6'
  workflow_dispatch:  # Allow manual trigger from GitHub UI

jobs:
  digest:
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Run digest pipeline
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
          GMAIL_ADDRESS: ${{ secrets.GMAIL_ADDRESS }}
          GMAIL_APP_PASSWORD: ${{ secrets.GMAIL_APP_PASSWORD }}
        run: python src/main.py
```

**Key Features:**
- `schedule` runs automatically on the cron
- `workflow_dispatch` allows manual runs from the GitHub UI (useful for testing)
- `timeout-minutes: 15` kills the job if it hangs
- Secrets are injected as environment variables â€” never in code

---

## 9. Future Extension Points

The architecture is intentionally simple, but these are the natural extension seams:

| Extension | Where It Plugs In | Complexity |
|-----------|-------------------|------------|
| **Additional arXiv categories** | `collector.py` â€” add categories to fetch list | Low |
| **Per-subscriber profiles** | `ranker.py` / `analyzer.py` â€” loop per profile | Medium |
| **Weekly digest mode** | `main.py` â€” aggregate multiple days before ranking | Low |
| **SendGrid/Resend** | `email_sender.py` â€” swap SMTP for API client | Low |
| **Paper history / dedup across days** | Add simple JSON or SQLite file | Low |
| **Slack/Teams delivery** | Add `slack_sender.py` alongside email sender | Medium |
| **Reading history feedback** | Track which papers users click â†’ refine profile | High |

---

## 10. Summary

| Aspect | Design Choice | Rationale |
|--------|---------------|-----------|
| **Architecture** | Linear pipeline, no framework | Simplest thing that works; easy to debug |
| **State** | Stateless between runs | No database to maintain; each run is independent |
| **LLM** | Claude 3.5 Sonnet for all calls | Best balance of quality, context window, and cost |
| **LLM Calls** | 7 per run | 1 ranking + 5 deep + 1 blurb batch |
| **PDF Extraction** | PyMuPDF primary, HTML fallback | Reliable text from any paper format |
| **Email** | Jinja2 template + Gmail SMTP | Simple, free, good enough for <50 subscribers |
| **Scheduling** | GitHub Actions cron | Free, zero-infrastructure, auto-retry |
| **Error Handling** | Error email + GH Actions logs | User always knows if something went wrong |
| **Estimated Cost** | ~$0.30â€“0.60/day | Well under $1/day budget |
| **Estimated Runtime** | ~4-7 minutes | Well under 15-minute budget |

